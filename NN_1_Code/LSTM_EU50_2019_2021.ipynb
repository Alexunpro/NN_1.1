{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHrKOz9ICE8S"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('EU50_2019_01_01_2021_01_01_10min.csv',  \n",
    "               names=['Date Time','StdDev','Open','Stoch0','Stoch1','CCI','Momentum','RSI','WPR','MACD','OsMA','BearsPower',] ,delimiter=';')#,  'BearsPower','TriX',  'BearsPower'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJkNEd6vCE8Z"
   },
   "outputs": [],
   "source": [
    "titles = [\n",
    "    \"StdDev\",\"Open\",\"Stoch0\",\"Stoch1\",\"CCI\",\"Momentum\",\"RSI\",\"WPR\",\"MACD\",\"OsMA\",\"BearsPower\",]#\"TriX\",\n",
    "\n",
    "feature_keys = [\n",
    "    \"StdDev\",\"Open\",\"Stoch0\",\"Stoch1\",\"CCI\",\"Momentum\",\"RSI\",\"WPR\",\"MACD\",\"OsMA\",\"BearsPower\",]#,\"TriX\"\n",
    "\n",
    "colors = [\n",
    "    \"blue\",\"orange\",\"green\",\"red\",\"purple\",\"brown\",\"pink\",\"gray\",\"olive\",\"cyan\",\"blue\",\"orange\",]\n",
    "\n",
    "date_time_key = \"Date Time\"\n",
    "\n",
    "\n",
    "def show_raw_visualization(data):\n",
    "    time_data = data[date_time_key]\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=7, ncols=2, figsize=(15, 20), dpi=80, facecolor=\"w\", edgecolor=\"k\"\n",
    "    )\n",
    "    for i in range(len(feature_keys)):\n",
    "        key = feature_keys[i]\n",
    "        c = colors[i % (len(colors))]\n",
    "        t_data = data[key]\n",
    "        t_data.index = time_data\n",
    "        t_data.head()\n",
    "        ax = t_data.plot(\n",
    "            ax=axes[i // 2, i % 2],\n",
    "            color=c,\n",
    "            title=\"{} - {}\".format(titles[i], key),\n",
    "            rot=25,\n",
    "        )\n",
    "        ax.legend([titles[i]])\n",
    "    plt.tight_layout()#\n",
    "\n",
    "show_raw_visualization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCpUFOkzCE8c"
   },
   "outputs": [],
   "source": [
    "#HEATMAP\n",
    "def show_heatmap(data):\n",
    "    plt.matshow(data.corr())\n",
    "    plt.xticks(range(data.shape[1]), data.columns, fontsize=14, rotation=90)\n",
    "    plt.gca().xaxis.tick_bottom()\n",
    "    plt.yticks(range(data.shape[1]), data.columns, fontsize=14)\n",
    "\n",
    "    cb = plt.colorbar()\n",
    "    cb.ax.tick_params(labelsize=14)\n",
    "    plt.title(\"Feature Correlation Heatmap\", fontsize=14)\n",
    "    plt.show()\n",
    "    \n",
    "    #show_heatmap(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVdaCAKzCE8d"
   },
   "outputs": [],
   "source": [
    "#NORMALISATION\n",
    "split_fraction = 0.715\n",
    "train_split = int(split_fraction * int(df.shape[0]))# 0.715 * 80932 = 57866\n",
    "step = 1# original  6\n",
    "\n",
    "past          = 720\n",
    "future        = 72\n",
    "learning_rate = 0.001\n",
    "batch_size    = 256\n",
    "epochs        = 3\n",
    "\n",
    "\n",
    "def normalize(data, train_split):\n",
    "    data_mean = data[:train_split].mean(axis = 0)\n",
    "    data_std  = data[:train_split].std (axis = 0)\n",
    "    return ((data - data_mean) / data_std)/2\n",
    "\n",
    " #Original\n",
    "#def normalize(data, train_split):\n",
    "    #data_mean = data[:train_split].mean(axis = 0)\n",
    "    #data_std  = data[:train_split].std (axis = 0)\n",
    "    #return (data - data_mean) / data_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRqX0Gx4CE8f"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The selected parameters are:\",\n",
    "    \", \".join([titles[i] for i in             [0, 1 ]])#,3,  5, 6, 7, 8, 10,  11]]),\n",
    ")\n",
    "selected_features = [feature_keys[i] for i in [0, 1 ]]# 3,  5, 6, 7, 8, 10,  11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features       = df[selected_features]\n",
    "features.index = df[date_time_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features       = normalize(features.values, train_split)\n",
    "features       = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data     = features.loc[0 : train_split - 1]\n",
    "val_data       = features.loc[train_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_BHcF8dCE8g"
   },
   "source": [
    "# Training dataset\n",
    "\n",
    "The training dataset labels starts from the 792nd observation (720 + 72)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vysFu7k9CE8h"
   },
   "outputs": [],
   "source": [
    "start = past  + future\n",
    "end   = start + train_split\n",
    "\n",
    "x_train = train_data[[i for i in range(2)]].values\n",
    "y_train = features.iloc[start:end][[1]]\n",
    "\n",
    "sequence_length = int(past / step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDkXF8EFCE8i"
   },
   "outputs": [],
   "source": [
    "dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    sequence_length = sequence_length,\n",
    "    sampling_rate   = step,\n",
    "    batch_size      = batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_end = len(val_data) - past - future\n",
    "label_start = train_split + past + future\n",
    "x_val = val_data.iloc[:x_end][[i for i in range(2)]].values\n",
    "y_val = features.iloc[label_start:][[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIlFgKj2CE8j"
   },
   "outputs": [],
   "source": [
    "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "\n",
    "for batch in dataset_train.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hAZPJyPCE8k"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VaAltAqgCE8k"
   },
   "outputs": [],
   "source": [
    "inputs   = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
    "lstm_out = keras.layers.LSTM(32)(inputs)\n",
    "outputs  = keras.layers.Dense(1)(lstm_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChLPGxf6CE8k"
   },
   "source": [
    "We'll use the `ModelCheckpoint` callback to regularly save checkpoints, and\n",
    "the `EarlyStopping` callback to interrupt training when the validation loss\n",
    "is not longer improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvzED2KfCE8l"
   },
   "outputs": [],
   "source": [
    "path_checkpoint = \"model_checkpoint.h5\"\n",
    "es_callback     = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n",
    "\n",
    "modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    monitor     = \"val_loss\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose     = 1,\n",
    "    save_weights_only = True,\n",
    "    save_best_only    = True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[es_callback, modelckpt_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_point_EU_50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SD7ddr9CE8m"
   },
   "source": [
    "We can visualize the loss with the function below. After one point, the loss stops\n",
    "decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUk9m0XKCE8m"
   },
   "outputs": [],
   "source": [
    "\n",
    "def visualize_loss(history, title):\n",
    "    loss     = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs   = range(len(loss))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_loss(history, \"Training and Validation Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huszW4V3CE8q"
   },
   "source": [
    "## Prediction\n",
    "\n",
    "The trained model above is now able to make predictions for 5 sets of values from\n",
    "validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wpc9gZlDCE8q"
   },
   "outputs": [],
   "source": [
    "\n",
    "def show_plot(plot_data, delta, title):\n",
    "    labels     = [\"History\", \"True Future\", \"Model Prediction\"]\n",
    "    marker     = [\".-\", \"rx\", \"go\"]\n",
    "    time_steps = list(range(-(plot_data[0].shape[0]), 0))\n",
    "    if delta:\n",
    "        future = delta\n",
    "    else:\n",
    "        future = 0\n",
    "\n",
    "    plt.title(title)\n",
    "    for i, val in enumerate(plot_data):\n",
    "        \n",
    "        \n",
    "        if i:\n",
    "            plt.plot(future, plot_data[i], marker[i], markersize=10, label=labels[i])\n",
    "        else:\n",
    "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "            \n",
    "            \n",
    "    plt.legend()\n",
    "    plt.xlim([time_steps[0], (future +5) * 2])\n",
    "    plt.xlabel(\"Time-Step\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "for x, y in dataset_val.take(5):#dataset_val\n",
    "    show_plot(\n",
    "        [x[0][:, 1].numpy(), y[0].numpy(), model.predict(x)[0]],#model.predict(x)[0]\n",
    "\n",
    "        12,\n",
    "        \"Single Step Prediction\"#(data - data_mean) / data_std\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "timeseries_weather_forecasting",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
